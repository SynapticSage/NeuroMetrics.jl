module shuffle

    import ..Timeshift
    import Field
    import Field.preset: field_presets, return_preset_funcs
    import Field: adaptive
    import Shuf
    import Utils: filtreg
    import Filt
    import Dates
    using DrWatson
    using Serialization

    using ThreadSafeDicts
    using DataFrames
    using DataStructures
    using ProgressMeter
    using LoopVectorization
    using Infiltrator

    export get_field_shift_shuffles

    # ≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡
    # COMPUTE THE a shuffle SETTING and distribute to downstream function
    # ≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡

    """
        get_field_shift_shuffles(beh::DataFrame, data::DataFrame,
                shifts::Union{StepRangeLen, Vector{T}} where T <: Real; 
                fieldpreset::Union{Symbol, NamedTuple, AbstractDict},
                shufflepreset::Union{Symbol, NamedTuple, AbstractDict},
                nShuffle::Int=100, 
                compute::Symbol=:single,
                postfunc::Union{Function,Nothing}=nothing,
                safe_dict::AbstractDict=ThreadSafeDict(),
                exfiltrateAfter::Real=Inf,
                get_field_kws...)::AbstractDict

    Overarching function that dispatches first to find a data generation
    process. and then it dispatches that process and keywords to a final
    function that takes the data generator for the shuffle (be it a
    distribution or permutation) to a function that repeats generation and
    measurement for the number of shuffles requested.

    """
    function shifted_field_shuffles(beh::DataFrame, data::DataFrame,
                shifts::Union{StepRangeLen, Vector{T}} where T <: Real,
                props::Vector; 
                shufflepreset::Union{Symbol, NamedTuple, AbstractDict},
                nShuffle::Int=100, 
                compute::Symbol=:single,
                postfunc::Union{Function,Nothing}=nothing,
                result_dict::AbstractDict=OrderedDict(),
                prefilter::Bool=true,
                skipproc::Bool=false,
                exfiltrateAfter::Real=Inf,
                shufStart::Int=1,
                get_field_kws...)::AbstractDict

        @info "Applying shufflepreset=$shufflepreset"
        initial_data_partials = Shuf.applyStandardShuffle(shufflepreset)

        if prefilter && :filters ∈ keys(get_field_kws)
            filters = get_field_kws[:filters]
           overwrite_precache = if :overwrite_precache ∈ keys(get_field_kws)
               overwrite_precache = pop!(get_field_kws, :overwrite_precache)
           else
               overwrite_precache = true
           end
            if Filt.filters_use_precache(filters) &&
                (overwrite_precache || Filt.missing_precache_col(data,
                                                                 filters))
                @info "shuffle data precaching"
                @time data = Filt.precache(data, beh, filters)
            end
            @info "shuffle data pre filtering"
            @time beh  = filtreg.filter(beh; filters, filter_skipmissingcols=true)[1]
            get_field_kws = (;get_field_kws..., filters=nothing)
        end

        _apply_partials(beh, data, shifts, props, initial_data_partials;
                        nShuffle, compute, postfunc, shufStart, skipproc,
                        result_dict, exfiltrateAfter, get_field_kws...)
    end

    # ≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡
    # Functions for distributing partial functionals that generate data
    # from the user settings
    # ≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡
    """
    Apply the partial functions derived from shuffle presets to fill in a
    shuffle generated by some statistical DISTRIBUTION
    """
    function _apply_partials(beh::DataFrame, data::DataFrame,
                shifts::Union{StepRangeLen,Vector{T}} where T <: Real,
                props::Vector,
                initial_data_partials::Tuple{<:Function,<:Function};
                nShuffle::Int=100, 
                skipproc::Bool=false,
                compute::Symbol=:single,
                postfunc::Union{Function,Nothing}=nothing,
                shufStart::Int=1,
                result_dict::AbstractDict=OrderedDict(),
                exfiltrateAfter::Real=Inf,
                field_kws...)::AbstractDict

        partial, dist = initial_data_partials
        distribution  = dist(data)
        shuffle_data_generator() = partial(data, distribution)

        _run_partial_functional(beh, data, shifts, shuffle_data_generator;
                                      compute, nShuffle, postfunc, result_dict,
                                      shufStart, skipproc,
                                      exfiltrateAfter, field_kws...)
    end

    """
    Apply the partial functions derived from shuffle presets to fill in a
    shuffle generated by a PERMUTATION
    """
    function _apply_partials(beh::DataFrame, data::DataFrame,
                shifts::Union{StepRangeLen,Vector{T}} where T <: Real,
                props::Vector,
                initial_data_partials::T where T <: Function;
                nShuffle::Int=100, 
                skipproc::Bool=false,
                compute::Symbol=:single,
                postfunc::Union{Function,Nothing}=nothing,
                shufStart::Int=1,
                result_dict::AbstractDict=OrderedDict(),
                exfiltrateAfter::Real=Inf,
                field_kws...)::AbstractDict

        partial = initial_data_partials
        shuffle_data_generator() = partial(data)

        _run_partial_functional(beh, data, shifts, props; 
                                      shuffle_data_generator, compute, nShuffle,
                                      postfunc, result_dict, exfiltrateAfter,
                                      shufStart, skipproc,
                                      field_kws...)
    end

    """
    takes a datagenerator and field/shift options to compute shuffled and
    shifted fields.
    """
    function _run_partial_functional(beh::DataFrame, data::DataFrame,
            shifts::Union{StepRangeLen,Vector{T}} where T <: Real,
            props::Vector; 
            shuffle_data_generator::Function,
            compute::Symbol, 
            nShuffle::Union{StepRangeLen, Int},
            shufStart::Int=1,
            result_dict::AbstractDict=OrderedDict{NamedTuple, 
                                                  Timeshift.DictOfShiftOfUnit{Float64}}(),
            saveAfter::Real=5,
            savename=nothing,
            skipproc::Bool=false,
            thread_field::Bool=true,
            precomputegridocc::Union{Bool,Nothing}=nothing,
            shiftbeh::Bool=false,
            field_kws...)

        @info "start" shufStart nShuffle savename saveAfter skipproc
        #@infiltrate shufStart > 1

        # Collect sets we will iterate
        if nShuffle isa Int
            shuffle_sets = collect(enumerate(1:nShuffle))
        else
            shuffle_sets = collect(enumerate(nShuffle))
        end

        P = Progress(length(nShuffle); desc="Shuffle")
        P.showspeed = true
        sizehint!(result_dict, maximum(nShuffle))

        nShuffle = nShuffle isa Int ? (shufStart:(nShuffle+shufStart-1)) : nShuffle
        @info "nShuffle" nShuffle

        if precomputegridocc === nothing
            precomputegridocc = shiftbeh ? false : true
        end

        if precomputegridocc
            grid = adaptive.get_grid(beh, props; field_kws...) # TODO these would be different for fixed
            occ  = adaptive.get_occupancy(beh, grid)
            field_kws = (;field_kws..., grid, occ)
        end

        prevtmp = nothing
        for s in nShuffle

            if skipproc && (;shuffle=s) ∈ keys(result_dict)
                continue
            end

            data   = shuffle_data_generator()
            
            tmp = Timeshift.shifted_fields(beh, data, 
                                           shifts, props;
                                           thread_field,
                                           shiftbeh, 
                                           field_kws...)

            result_dict[(;shuffle=s)] = tmp
            isdefined(Main, :PlutoRunner) ? @info("finished 1 shuf") : nothing
            @info "modulus" mod(s,saveAfter)
            if mod(s, saveAfter) == 0
                if savename === nothing
                    @info "Exfiltrating"
                    @exfiltrate
                else
                    dShuf = maximum(nShuffle) - minimum(nShuffle)
                    K = collect(keys(result_dict))[max(s-dShuf,1):s]
                    chfile = datadir("checkpoints","shuffle_$(savename)_$(Dates.now()).serial")
                    @info "SERIALIZING" chfile K
                    @time serialize(chfile, OrderedDict(k=>result_dict[k] for k in K))
                end
            end
            next!(P)
            #prevtmp = tmp
        end

        #safe_dict = Dict(result_dict...)
        #OrderedDict(key=>pop!(safe_dict, key) 
        #                  for key in sort([keys(safe_dict)...]))
        result_dict
    end

end
